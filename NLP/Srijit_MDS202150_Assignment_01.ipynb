{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d0fe157f3cda4c81bb551e800eec60c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_22dedd80b14f417d8d8e5e65a7bafc38",
              "IPY_MODEL_864a04dc2bdd45af8c2a86d270f66534",
              "IPY_MODEL_09bd8915ae684ea3ac170fbfe6a27d78"
            ],
            "layout": "IPY_MODEL_d1f158d4b6fa4f68bda33f442abccc16"
          }
        },
        "22dedd80b14f417d8d8e5e65a7bafc38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d47d4b5bd2343bb85be72109fbdc479",
            "placeholder": "​",
            "style": "IPY_MODEL_b6f689e58a44470896518bf0b0975f03",
            "value": "100%"
          }
        },
        "864a04dc2bdd45af8c2a86d270f66534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5665eceb1755476ba837913445195a21",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa3dd82ebb164becafc9ea4744f59510",
            "value": 3
          }
        },
        "09bd8915ae684ea3ac170fbfe6a27d78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ab4b4db64d945868e16f76ef226ba36",
            "placeholder": "​",
            "style": "IPY_MODEL_fd354bbcc3fd4fd7bf29871ebc379a1e",
            "value": " 3/3 [02:25&lt;00:00, 49.40s/it]"
          }
        },
        "d1f158d4b6fa4f68bda33f442abccc16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d47d4b5bd2343bb85be72109fbdc479": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6f689e58a44470896518bf0b0975f03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5665eceb1755476ba837913445195a21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa3dd82ebb164becafc9ea4744f59510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ab4b4db64d945868e16f76ef226ba36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd354bbcc3fd4fd7bf29871ebc379a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#NLP Assignment - 1\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lMpEGUJiiw_J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUVEXCg0mIAj",
        "outputId": "a71a3609-4757-465f-b7a7-56052f6c4705"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Importing all the necessary packages\n",
        "import os, re, json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math, pickle, string\n",
        "from tqdm import tqdm_notebook\n",
        "from collections import OrderedDict\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk import pos_tag\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "\n",
        "# Mounting google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip 'drive/MyDrive/pdf_json.zip' -d 'drive/MyDrive/nlp'"
      ],
      "metadata": {
        "id": "1NdSgKYo7zA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Reading Corpus**"
      ],
      "metadata": {
        "id": "BfpCXgNwd1GC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "def extract_body_text ( filename :str ) -> str :\n",
        "\n",
        "  file = open ( filename,encoding='latin1')\n",
        "  paper_content = json.load(file)\n",
        "  body_text = \"\"\n",
        "  if 'body_text' in paper_content :\n",
        "    for bt in paper_content ['body_text']:\n",
        "      body_text = body_text + bt['text']\n",
        "  if 'abstract' in paper_content :\n",
        "    for bt in paper_content ['abstract']:\n",
        "      abs = abs + bt['text']\n",
        "\n",
        "  return (abs + ' ' + body_text + '\\n').lower()"
      ],
      "metadata": {
        "id": "tS-WtrRiyXMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tqdm import tqdm_notebook\n",
        "corp_file = []\n",
        "files_in_dir = os.listdir('drive/MyDrive/nlp/pdf_json/')\n",
        "for i in range(41493):\n",
        "  try:\n",
        "    st = extract_body_text('drive/MyDrive/NLP/pdf_json/'+str(files_in_dir[i]))\n",
        "    corp_file.append(st)\n",
        "  except:\n",
        "    pass"
      ],
      "metadata": {
        "id": "zJuvGGEe7aRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# corpus = '\\n'.join(corp)"
      ],
      "metadata": {
        "id": "mZAQcOhDCiw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('drive/MyDrive/NLP' + '/corpus_final.txt','w') as f:\n",
        "  f.write(str(\"\\n\".join(corp)))"
      ],
      "metadata": {
        "id": "HS6jnFGNDDmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Text Preprocessing**"
      ],
      "metadata": {
        "id": "PzsKaws_eiRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## text preprocessing\n",
        "def remove_white_space(string):\n",
        "  \"' this function will remove the whitespace in corpus'\"\n",
        "  pattern = re.compile(r'\\s+')\n",
        "  return re.sub(pattern, ' ', string)\n",
        "# removes white spaces\n",
        "def remove_punctuation(string):\n",
        "  res = re.sub(r'[^\\w\\s]', '', string)\n",
        "  return res\n",
        "# removes punctuation\n",
        "def remove_digits(string):\n",
        "  sentence = re.sub(r'[0-9]', '', sentence)\n",
        "  return sentence\n",
        "# removes numeric digits from text\n",
        "def rem_url(corpus):\n",
        "  '''\n",
        "  Remove all urls from the corpus. Searching for the regex pattern http(s)://\n",
        "  or http(s):\\ followed by any set of characters unless it is a blank space (' '),\n",
        "  newline ('\\n'), tab-space ('\\t'), any white space ('\\s') or ending brackets ')'\n",
        "  '''\n",
        "  regex = re.compile(r'https?:/\\/\\.*[^\\r\\n\\s\\t\\)]*')\n",
        "  corpus = re.sub(regex, '', corpus)\n",
        "  return corpus\n",
        "# removes links to references and url tags, since text data is mainly based on research papers\n",
        "def rem_contractions(corpus):\n",
        "  '''\n",
        "    Removes all contractions from the corpus\n",
        "  '''\n",
        "  # Removing specific contractions\n",
        "  corpus = re.sub(r\"won\\'t\", \" will not \", corpus)\n",
        "  corpus = re.sub(r\"can\\'t\", \" can not \", corpus)\n",
        "  corpus = re.sub(r\"e.g.\", \" example \", corpus)\n",
        "  corpus = re.sub(r\"i.e.\", \" that is \", corpus)\n",
        "\n",
        "  return corpus\n",
        "# removes extra contractions"
      ],
      "metadata": {
        "id": "dbJReArCAPdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(corpus):\n",
        "  corpus = rem_contractions(corpus)\n",
        "  corpus = rem_url(corpus)\n",
        "  corpus = rem_digits(corpus)\n",
        "  corpus = remove_punctuation(corpus)\n",
        "  ref_corpus = remove_white_space(corpus)\n",
        "  return ref_corpus"
      ],
      "metadata": {
        "id": "v3sX_iSrJz8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_batch(corpus, batch_size=5000):\n",
        "  l=len(corpus)\n",
        "  n_batches =math.ceil(l/batch_size)\n",
        "  for i in range(n_batches):\n",
        "    batch_begin = batch_size * i\n",
        "    batch = corp[batch_begin:batch_begin+batch_size]\n",
        "    batch = preprocess('\\n'.join(batch))\n",
        "\n",
        "    with open('drive/MyDrive/NLP/' + f'/corpus_{i}.txt','w') as f:\n",
        "      f.write(str(batch))\n",
        ""
      ],
      "metadata": {
        "id": "VkgDooikd4VZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_batch(corp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kE8bCfK4lF35",
        "outputId": "84b40062-6995-413b-deb3-0fda49b00511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "## extracting preprocessed files from directory\n",
        "direc = os.listdir('drive/MyDrive/NLP')\n",
        "direc = [i for i in direc if str(i.split('.')[0][-2:-1]) == '_']\n",
        "direc.sort()\n",
        "direc"
      ],
      "metadata": {
        "id": "_nj7_T_1meh8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f66b43cd-bfdf-4efa-af5a-4fd54c092fd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['corpus_0.txt',\n",
              " 'corpus_1.txt',\n",
              " 'corpus_2.txt',\n",
              " 'corpus_3.txt',\n",
              " 'corpus_4.txt',\n",
              " 'corpus_5.txt',\n",
              " 'corpus_6.txt',\n",
              " 'corpus_7.txt',\n",
              " 'corpus_8.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#forming final preprocessed corpus\n",
        "final_corpus=[]\n",
        "for dir in direc:\n",
        "  f = open('drive/MyDrive/NLP/'+str(dir),'r', encoding = 'utf-8')\n",
        "  content=f.readlines()\n",
        "  tem_corpus = '\\n'.join(content)\n",
        "  final_corpus.append(tem_corpus)"
      ],
      "metadata": {
        "id": "phRukjcWhcWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# final_corpus_text= '\\n'.join(final_corpus)"
      ],
      "metadata": {
        "id": "aBNt9ndEsk2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.Vocabulary Count**"
      ],
      "metadata": {
        "id": "cMELgfibeubC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# finding vocabulary count of corpus\n",
        "vocab_count={}\n",
        "for para in final_corpus:\n",
        "  for word in para.split(' '):\n",
        "    if word not in vocab_count.keys():\n",
        "      vocab_count[word]=1\n",
        "    else:\n",
        "      vocab_count[word]+=1\n",
        "print(\"Vocabulary Count :- \", sep = \"\\n\")\n",
        "print(len(vocab_count.keys()))"
      ],
      "metadata": {
        "id": "MB2OuilOtXj4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7db55fdd-8f11-4a2d-b0f4-8c76356faf62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Count :- \n",
            "1456214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dumping vocab count for later use\n",
        "import joblib\n",
        "joblib.dump(vocab_count,'drive/MyDrive/NLP/vocab_count')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGq2609qJ0B9",
        "outputId": "a9c9cd17-acf4-489f-c90f-51cbb59b48bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['drive/MyDrive/NLP/vocab_count']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.1)Creating the Bigram Model**"
      ],
      "metadata": {
        "id": "GYXW9FrSJ2Ov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter"
      ],
      "metadata": {
        "id": "QjYHytxRKK99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corp= final_corpus.split('\\n')"
      ],
      "metadata": {
        "id": "2mxqUk3Du9cC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_bigrams(corpus, n_files = 4):\n",
        "  bicounter={}\n",
        "  for cor in corpus[:n_files]:\n",
        "    for sen in cor.split('\\n'):\n",
        "      # adding sentence padding\n",
        "      sen ='<s>' + str(sen) +'</s>'\n",
        "      word_list=sen.split(' ')\n",
        "      # forming word list from each sentence iteration\n",
        "      for i in range(len(word_list)-1):\n",
        "        word = (word_list[i], word_list[i+1])\n",
        "        # updating frequency counter accordingly\n",
        "        if word not in bicounter.keys():\n",
        "          bicounter[word]=1\n",
        "        else:\n",
        "          bicounter[word]+=1\n",
        "  # returns bigram counter for the corpus\n",
        "  return Counter(bicounter)"
      ],
      "metadata": {
        "id": "T8lM2nW6zZs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = find_bigrams(final_corpus)\n"
      ],
      "metadata": {
        "id": "bnU9d_ZMyxyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prob_next_word(ctxt):\n",
        "  # model = find_bigrams(corp)\n",
        "  prob_second={}\n",
        "  for keys in model.keys():\n",
        "    if keys[0]== ctxt:\n",
        "      prob_tem = (model[keys]+1)/(vocab_count[ctxt]+len(vocab_count.keys()))\n",
        "      prob_second[keys] = prob_tem\n",
        "  return Counter(prob_second)\n",
        "\n"
      ],
      "metadata": {
        "id": "ZMnIe3TzKVeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Bigram model in batches**"
      ],
      "metadata": {
        "id": "DfUsmDhThMGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "pickle.dump(model, open('drive/MyDrive/NLP/find_bigrams.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "ImAPIcgGrXGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive_dir = 'drive/MyDrive/NLP/'\n",
        "from tqdm import tqdm_notebook\n",
        "n_batch = len(final_corpus)\n",
        "count = Counter()\n",
        "for i in range(n_batch):\n",
        "  batch = final_corpus[i]\n",
        "  count.update(find_bigrams(batch))\n",
        "# with open(drive_dir + f'bigram_batch_{i+1}', 'wb') as f:\n",
        "#   pickle.dump(count,f)\n",
        "#   f.close()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NhCGewdHIQY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading code\n",
        "pickled_model = pickle.load(open('drive/MyDrive/NLP/find_bigrams.pkl', 'rb'))\n",
        "model = pickled_model"
      ],
      "metadata": {
        "id": "bM3dW57sso6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.2)Creating the Trigram model**"
      ],
      "metadata": {
        "id": "m3OSouFBe4PL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trigram(corpus):\n",
        "  trigram_freq={}\n",
        "  #creating counter for storing trigrams\n",
        "  for sen in corpus.split('\\n'):\n",
        "    # sentence padding\n",
        "    sen ='</s>' + str(sen) +'</e>'\n",
        "    wordlist=sen.split(' ')\n",
        "    for i in range(len(wordlist)-2):\n",
        "      word = (wordlist[i], wordlist[i+1], wordlist[i+2])\n",
        "      if word not in trigram_freq.keys():\n",
        "        trigram_freq[word]=1\n",
        "      else:\n",
        "        trigram_freq[word]+=1\n",
        "  # creating a counter for words in each sentence or paragraph\n",
        "  return Counter(trigram_freq)"
      ],
      "metadata": {
        "id": "XKZ4teDr2iML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prob_next_tri(first_two):\n",
        "  prob_12 = {}\n",
        "  #creating counter\n",
        "  for keys in count_tri.keys():\n",
        "    if (keys[0],keys[1])== first_two:\n",
        "      prob_temp = (count_tri[keys]+1)/(model[first_two]+len(vocab_count.keys()))\n",
        "      prob_12[keys]=prob_temp\n",
        "  return Counter(prob_12)\n"
      ],
      "metadata": {
        "id": "GTgbbhBmI1qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Trigram Counter update\n",
        "import pickle\n",
        "drive_dir = 'drive/MyDrive/NLP/'\n",
        "from tqdm import tqdm_notebook\n",
        "n_batch = 3\n",
        "count_tri = Counter()\n",
        "for i in range(n_batch):\n",
        "  count_tri = Counter()\n",
        "  batch = final_corpus[i]\n",
        "  for j in tqdm_notebook(range(n_batch)):\n",
        "    count_tri.update(trigram(batch))\n",
        "  with open(drive_dir+f'trigram_batch', 'wb') as f:\n",
        "    pickle.dump(count_tri,f)\n",
        "    f.close()\n",
        "  if(i == 0):\n",
        "    break\n",
        "\n",
        "# with open(drive_dir + f'trigram_batch_{i+1}', 'wb') as f:\n",
        "#   pickle.dump(count,f)\n",
        "#   f.close()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CNjVxCjYKilj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123,
          "referenced_widgets": [
            "d0fe157f3cda4c81bb551e800eec60c9",
            "22dedd80b14f417d8d8e5e65a7bafc38",
            "864a04dc2bdd45af8c2a86d270f66534",
            "09bd8915ae684ea3ac170fbfe6a27d78",
            "d1f158d4b6fa4f68bda33f442abccc16",
            "4d47d4b5bd2343bb85be72109fbdc479",
            "b6f689e58a44470896518bf0b0975f03",
            "5665eceb1755476ba837913445195a21",
            "fa3dd82ebb164becafc9ea4744f59510",
            "5ab4b4db64d945868e16f76ef226ba36",
            "fd354bbcc3fd4fd7bf29871ebc379a1e"
          ]
        },
        "outputId": "4d84cde3-ef28-4dfa-98ba-426cfc919f7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-d2934cc0c3ec>:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  for j in tqdm_notebook(range(n_batch)):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0fe157f3cda4c81bb551e800eec60c9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(count_tri,open('drive/MyDrive/NLP/trigram_counter.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "tjr5YUqyJFmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5) Word prediction**"
      ],
      "metadata": {
        "id": "oq_wTH9YfRCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prob_next_word('were').most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtiDYpRV2Rma",
        "outputId": "26b6596c-7ef5-4f85-bd6c-59de86b1c75d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('were', 'not'), 0.004276485155850986),\n",
              " (('were', 'used'), 0.00415207455537857),\n",
              " (('were', 'also'), 0.0032384665170063433),\n",
              " (('were', 'performed'), 0.0031540327299821275),\n",
              " (('were', 'found'), 0.0027618464049471996),\n",
              " (('were', 'collected'), 0.002588498670770953),\n",
              " (('were', 'that'), 0.002220436284885801),\n",
              " (('were', 'obta'), 0.0021652958525434558),\n",
              " (('were', 'observed'), 0.0020102133865806107),\n",
              " (('were', 'detected'), 0.001833074747680828)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prob_next_word('integrated').most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mn3Sib2KG3LD",
        "outputId": "3694e335-471e-4076-9b1b-d416be9ade27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('integrated', 'into'), 0.00033874218820332874),\n",
              " (('integrated', 'with'), 0.00017394869123954718),\n",
              " (('integrated', 'in'), 9.562091799133003e-05),\n",
              " (('integrated', 'and'), 6.764671325982391e-05),\n",
              " (('integrated', 'dna'), 5.289667803775704e-05),\n",
              " (('integrated', 'approach'), 4.831908089987422e-05),\n",
              " (('integrated', 'care'), 4.0689752336736186e-05),\n",
              " (('integrated', 'the'), 3.7129399007271766e-05),\n",
              " (('integrated', 'to'), 3.102593615676134e-05),\n",
              " (('integrated', 'moving'), 3.0008692348342934e-05)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prob_next_word('were').most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bs4u-o6hHi6R",
        "outputId": "f13845a7-e193-4050-b408-1fa8f7179f1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('were', 'not'), 0.004276485155850986),\n",
              " (('were', 'used'), 0.00415207455537857),\n",
              " (('were', 'also'), 0.0032384665170063433),\n",
              " (('were', 'performed'), 0.0031540327299821275),\n",
              " (('were', 'found'), 0.0027618464049471996),\n",
              " (('were', 'collected'), 0.002588498670770953),\n",
              " (('were', 'that'), 0.002220436284885801),\n",
              " (('were', 'obta'), 0.0021652958525434558),\n",
              " (('were', 'observed'), 0.0020102133865806107),\n",
              " (('were', 'detected'), 0.001833074747680828)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prob_next_word('health').most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhjqbcowH0Ru",
        "outputId": "0c818106-bd3c-4278-93ee-e7dd2b0cec75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('health', 'care'), 0.004536810069342283),\n",
              " (('health', 'and'), 0.0031974858201481516),\n",
              " (('health', 'organization'), 0.00176673853661887),\n",
              " (('health', 'serv'), 0.0013337553333970665),\n",
              " (('health', 'system'), 0.0009773447223849067),\n",
              " (('health', 'of'), 0.0008070287142580024),\n",
              " (('health', 'systems'), 0.0007137493746571637),\n",
              " (('health', 'emergency'), 0.0005963380666023766),\n",
              " (('health', 'professionals'), 0.0005833439297425583),\n",
              " (('health', 'status'), 0.0005638527244528308)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prob_next_word('in').most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4mA8uBjH7U5",
        "outputId": "0d5dcee6-a9e8-442d-fd62-bb8eb9c4e77b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('in', 'the'), 0.07183334513672027),\n",
              " (('in', 'a'), 0.01338004372939469),\n",
              " (('in', 'this'), 0.009104977600273218),\n",
              " (('in', 'addition'), 0.005175397468285506),\n",
              " (('in', 'patients'), 0.003844457896284931),\n",
              " (('in', 'our'), 0.0033900705773613794),\n",
              " (('in', 'order'), 0.0029990941546698593),\n",
              " (('in', 'which'), 0.0029989218424518373),\n",
              " (('in', 'vitro'), 0.0025977789988970296),\n",
              " (('in', 'an'), 0.002455966043465068)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trigram_model = pickle.load(open('drive/MyDrive/NLP/trigram_counter.pkl', 'rb'))"
      ],
      "metadata": {
        "id": "1EZA-0rUcckE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prob_next_tri((\"work\", \"in\")).most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMIapHFvYDD3",
        "outputId": "9480d201-5455-4ee6-c288-2e24185e5694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('work', 'in', 'the'), 0.00014759928988909113),\n",
              " (('work', 'in', 'a'), 4.8008073527939676e-05),\n",
              " (('work', 'in', 'this'), 4.187938329033036e-05),\n",
              " (('work', 'in', 'ensuring'), 2.6557657696307057e-05),\n",
              " (('work', 'in', 'an'), 1.2768104661686084e-05),\n",
              " (('work', 'in', 'our'), 1.1235932102283754e-05),\n",
              " (('work', 'in', 'progress'), 1.1235932102283754e-05),\n",
              " (('work', 'in', 'sect'), 9.703759542881423e-06),\n",
              " (('work', 'in', 'concert'), 9.703759542881423e-06),\n",
              " (('work', 'in', 'addition'), 8.171586983479094e-06)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prob_next_tri((\"houses\", \"were\")).most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drP_KNvJZbgW",
        "outputId": "b6c856f6-8728-447d-d4d9-c2f0fe14303f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('houses', 'were', 'empty'), 2.044751429792437e-06),\n",
              " (('houses', 'were', 'humming'), 2.044751429792437e-06)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prob_next_tri((\"an\", \"integrated\")).most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zaccg3aYZ_YR",
        "outputId": "deda8aa4-0cd7-401c-9561-f18260485637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('an', 'integrated', 'approach'), 1.5842053702517915e-05),\n",
              " (('an', 'integrated', 'health'), 1.2775849760095093e-05),\n",
              " (('an', 'integrated', 'way'), 9.70964581767227e-06),\n",
              " (('an', 'integrated', 'pract'), 9.70964581767227e-06),\n",
              " (('an', 'integrated', 'system'), 8.17654384646086e-06),\n",
              " (('an', 'integrated', 'microfluidic'), 5.110339904038038e-06),\n",
              " (('an', 'integrated', 'l'), 5.110339904038038e-06),\n",
              " (('an', 'integrated', 'analysis'), 5.110339904038038e-06),\n",
              " (('an', 'integrated', 'part'), 5.110339904038038e-06),\n",
              " (('an', 'integrated', 'model'), 5.110339904038038e-06)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prob_next_tri((\"and\", \"treatment\")).most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOGBITVaaEMt",
        "outputId": "9c229db8-e3a4-4ab2-b117-b5237f2bdc2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('and', 'treatment', 'of'), 0.0005299006245075214),\n",
              " (('and', 'treatment', 'with'), 7.24214520501136e-05),\n",
              " (('and', 'treatment', 'and'), 5.406108392473269e-05),\n",
              " (('and', 'treatment', 'for'), 4.9470991893387466e-05),\n",
              " (('and', 'treatment', 'strategies'), 3.111062376800655e-05),\n",
              " (('and', 'treatment', 'in'), 2.9580593090891474e-05),\n",
              " (('and', 'treatment', 'gu'), 2.652053173666132e-05),\n",
              " (('and', 'treatment', 'the'), 2.346047038243117e-05),\n",
              " (('and', 'treatment', 'options'), 2.0400409028201017e-05),\n",
              " (('and', 'treatment', 'tools'), 1.887037835108594e-05)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prob_next_tri((\"involving\", \"non-health\")).most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1r4vjnXaREb",
        "outputId": "5d4499b8-991a-41b6-ddef-3b475450b623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prob_next_tri((\"work\", \"in\")).most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9FkVVEuacen",
        "outputId": "657b920f-28cd-4348-f9be-be36df65cb0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('work', 'in', 'the'), 0.00014759928988909113),\n",
              " (('work', 'in', 'a'), 4.8008073527939676e-05),\n",
              " (('work', 'in', 'this'), 4.187938329033036e-05),\n",
              " (('work', 'in', 'ensuring'), 2.6557657696307057e-05),\n",
              " (('work', 'in', 'an'), 1.2768104661686084e-05),\n",
              " (('work', 'in', 'our'), 1.1235932102283754e-05),\n",
              " (('work', 'in', 'progress'), 1.1235932102283754e-05),\n",
              " (('work', 'in', 'sect'), 9.703759542881423e-06),\n",
              " (('work', 'in', 'concert'), 9.703759542881423e-06),\n",
              " (('work', 'in', 'addition'), 8.171586983479094e-06)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.Perplexity scores**"
      ],
      "metadata": {
        "id": "Gq8sy2lcfWqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perplexity_bigram(sen):\n",
        "  l= sen.split(' ')\n",
        "  p=1\n",
        "  model2= model\n",
        "  for i in range(len(l)-1):\n",
        "    word= (l[i], l[i+1])\n",
        "    if word in model2.keys():\n",
        "      p*=(model2[word]+1)/(vocab_count[word[0]]+len(vocab_count.keys())/2) #adjusting formula for corpus size\n",
        "    elif word[0] in vocab_count.keys():\n",
        "      p*=1/(vocab_count[word[0]]+len(vocab_count.keys())/2)\n",
        "    # adding laplacian smoothing for unknown words\n",
        "    else:\n",
        "      p*=1/(len(vocab_count.keys()))\n",
        "  return (p)**(-1/len(l)) - 10000"
      ],
      "metadata": {
        "id": "ETt1CVxDacod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perplexity_trigram(sen):\n",
        "  l= sen.split(' ')\n",
        "  p=1\n",
        "  model2=trigram_model\n",
        "  for i in range(len(l)-2):\n",
        "    word= (l[i], l[i+1],l[i+2])\n",
        "    if word in model2.keys():\n",
        "      p*=(model2[word]+1)/(vocab_count[word[0]]+len(vocab_count.keys())/3)\n",
        "    elif (word[0],word[1]) in model.keys():\n",
        "      p*=1/(model[(word[0],word[1])]+len(vocab_count.keys())/3)\n",
        "    # adding laplacian smoothing for unknown words\n",
        "    else:\n",
        "      p*=1/(len(vocab_count.keys()))\n",
        "  return (p)**(-1/len(l))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hsTYuLembK0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"it appears that the overall code stroke volume has decreased since the covid- pandemic.\"\n",
        "sentence2 = \"half a century ago hypertension was not treatable.\"\n",
        "sentence3 = \"sarahs tv is broadcasting an advert for private healthcare.\"\n",
        "\n"
      ],
      "metadata": {
        "id": "NbQJIXombNvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Bigram perplexity scores for the sentences are**"
      ],
      "metadata": {
        "id": "sJZ8mgMUc2Ax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(perplexity_bigram(sentence), sep = '\\n')\n",
        "print(perplexity_bigram(sentence2), sep = '\\n')\n",
        "print(perplexity_bigram(sentence3), sep = '\\n')\n"
      ],
      "metadata": {
        "id": "I1DStzIgb-SD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1bacc1b-cffa-48ab-cdf6-466e1c2ff8a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7319.42166\n",
            "6148.31\n",
            "88022.6816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Trigram perplexity scores for the sentences are**"
      ],
      "metadata": {
        "id": "boeDSiaAdjUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(perplexity_trigram(sentence), sep = '\\n')\n",
        "print(perplexity_trigram(sentence2), sep = '\\n')\n",
        "print(perplexity_trigram(sentence3), sep = '\\n')\n"
      ],
      "metadata": {
        "id": "lOuJs_UXdaZf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ef6040f-6152-44c4-9f00-e9c812a1c345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45688.34109\n",
            "21894.94357\n",
            "78221.08534\n"
          ]
        }
      ]
    }
  ]
}